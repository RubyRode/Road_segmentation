{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "23d73ed9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-18T04:42:37.785216400Z",
     "start_time": "2023-05-18T04:42:35.940937900Z"
    }
   },
   "outputs": [],
   "source": [
    "# imports\n",
    "import torch.nn as nn\n",
    "import torchvision.transforms.functional as TF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "b1051383",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-18T04:49:59.718169400Z",
     "start_time": "2023-05-18T04:49:59.701138Z"
    }
   },
   "outputs": [],
   "source": [
    "# Define model class\n",
    "\n",
    "class Residual(nn.Module):\n",
    "    def __init__(self, in_c, out_c):\n",
    "        super(Residual, self).__init__()\n",
    "        self.in_c = in_c\n",
    "        self.out_c = out_c\n",
    "        self.conv = nn.Sequential(\n",
    "            nn.Conv2d(in_c, out_c, 1, 1, 0, bias=False),\n",
    "            nn.BatchNorm2d(out_c),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(out_c, out_c, 3, 1, 1, bias=False),\n",
    "            nn.BatchNorm2d(out_c),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(out_c, in_c, 3, 1, 1, bias=False),\n",
    "            #\n",
    "            # nn.Conv2d(in_c, out_c, 3, 1, 1, bias=False),\n",
    "            # nn.BatchNorm2d(out_c),\n",
    "            # nn.ReLU(inplace=True),\n",
    "            # nn.Conv2d(out_c, out_c, 3, 1, 1, bias=False),\n",
    "            # nn.BatchNorm2d(out_c),\n",
    "            # nn.ReLU(inplace=True),\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        tmp = self.conv(x)\n",
    "        x += tmp\n",
    "        return nn.Conv2d(self.in_c, self.out_c, 1, 1, 0, bias=False, device='cuda:0')(x)\n",
    "    \n",
    "class Unet(nn.Module):\n",
    "    def __init__ (\n",
    "        self,\n",
    "        in_c=3,\n",
    "        out_c=1,\n",
    "        features=None\n",
    "    ):\n",
    "        super(Unet, self).__init__()\n",
    "        if features is None:\n",
    "            features = [\n",
    "                64,\n",
    "                128,\n",
    "                256,\n",
    "                512\n",
    "            ]\n",
    "        self.up = nn.ModuleList()\n",
    "        self.down = nn.ModuleList()\n",
    "        self.pool = nn.MaxPool2d(2,2)\n",
    "        for feature in features:\n",
    "            self.down.append(Residual(in_c, feature))\n",
    "            in_c = feature\n",
    "        \n",
    "        for feature in reversed(features):\n",
    "            self.up.append(\n",
    "                nn.ConvTranspose2d(\n",
    "                    feature * 2, feature, kernel_size=2, stride=2\n",
    "                )\n",
    "            )\n",
    "            self.up.append(Residual(feature * 2, feature))\n",
    "        \n",
    "        self.bottleneck = Residual(features[-1], features[-1] * 2)\n",
    "        self.final_conv = nn.Conv2d(features[0], out_c, kernel_size=1)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        skip_connections = []\n",
    "\n",
    "        for down in self.down:\n",
    "            x = down(x)\n",
    "            skip_connections.append(x)\n",
    "            x = self.pool(x)\n",
    "\n",
    "        x = self.bottleneck(x)\n",
    "        skip_connections = skip_connections[::-1]\n",
    "\n",
    "        for idx in range(0, len(self.up), 2):\n",
    "            x = self.up[idx](x)\n",
    "            skip_connection = skip_connections[idx//2]\n",
    "\n",
    "            if x.shape != skip_connection.shape:\n",
    "                x = TF.resize(x, size=skip_connection.shape[2:])\n",
    "\n",
    "            concat_skip = torch.cat((skip_connection, x), dim=1)\n",
    "            x = self.up[idx+1](concat_skip)\n",
    "\n",
    "        return self.final_conv(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "3462b45b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-18T04:50:00.036687700Z",
     "start_time": "2023-05-18T04:50:00.014689400Z"
    }
   },
   "outputs": [],
   "source": [
    "# Define Dataset class\n",
    "import os\n",
    "from PIL import Image\n",
    "from torch.utils.data import Dataset\n",
    "import numpy as np\n",
    "\n",
    "class RoadDataset(Dataset):\n",
    "    def __init__(self, image_dir, mask_dir, transform=None):\n",
    "        self.image_dir = image_dir\n",
    "        self.mask_dir = mask_dir\n",
    "        self.transform = transform\n",
    "        self.images = os.listdir(image_dir)\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        img_path = os.path.join(self.image_dir, self.images[index])\n",
    "        mask_path = os.path.join(self.mask_dir, self.images[index])\n",
    "        image = np.array(Image.open(img_path).convert(\"RGB\"))\n",
    "        mask = np.array(Image.open(mask_path).convert(\"L\"), dtype=np.float32)\n",
    "        mask[mask == 255.0] = 1.0\n",
    "        if self.transform is not None:\n",
    "            aug = self.transform(image=image, mask=mask)\n",
    "            image = aug['image']\n",
    "            mask = aug['mask']\n",
    "        return image, mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "0568025d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-18T04:50:00.454904200Z",
     "start_time": "2023-05-18T04:50:00.436906100Z"
    }
   },
   "outputs": [],
   "source": [
    "# Helper functions\n",
    "import torchvision\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "def save_checkpoint(state, filename):\n",
    "    print(f\"===> Saving checkpoint {filename}\")\n",
    "    torch.save(state, filename)\n",
    "\n",
    "def get_loaders(\n",
    "    train_dir,\n",
    "    train_mask_dir,\n",
    "    val_dir,\n",
    "    val_mask_dir,\n",
    "    batch_size,\n",
    "    train_transform,\n",
    "    val_transform,\n",
    "    # num_workers=4,\n",
    "    pin_memory=True,\n",
    "):\n",
    "    train_ds = RoadDataset(\n",
    "        image_dir=train_dir,\n",
    "        mask_dir=train_mask_dir,\n",
    "        transform=train_transform\n",
    "    )\n",
    "\n",
    "    \n",
    "    train_loader = DataLoader(\n",
    "        train_ds, \n",
    "        batch_size=batch_size, \n",
    "        # num_workers=num_workers,\n",
    "        pin_memory=pin_memory, \n",
    "        shuffle=True\n",
    "    )\n",
    "    \n",
    "    val_ds = RoadDataset(\n",
    "        image_dir=val_dir,\n",
    "        mask_dir=val_mask_dir,\n",
    "        transform=val_transform,\n",
    "    )\n",
    "    \n",
    "    val_loader = DataLoader(\n",
    "        val_ds,\n",
    "        batch_size=batch_size,\n",
    "        # num_workers=num_workers,\n",
    "        pin_memory=pin_memory,\n",
    "        shuffle=False,\n",
    "    )\n",
    "    \n",
    "    return train_loader, val_loader\n",
    "\n",
    "\n",
    "class DiceLoss(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(DiceLoss, self).__init__()\n",
    "\n",
    "    def forward(self, input, target):\n",
    "        smooth = 1.\n",
    "        iflat = input.contiguous().view(-1)\n",
    "        tflat = target.contiguous().view(-1)\n",
    "        intersection = (iflat * tflat).sum()\n",
    "\n",
    "        return 1 - ((2. * intersection + smooth) /\n",
    "                  (iflat.sum() + tflat.sum() + smooth))\n",
    "\n",
    "\n",
    "def check_accuracy(loader, model, device=\"cuda\"):\n",
    "    num_correct = 0\n",
    "    num_pixels = 0\n",
    "    dice_score = 0\n",
    "    model.eval()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for x, y in loader:\n",
    "            x = x.to(device)\n",
    "            y = y.to(device).unsqueeze(1)\n",
    "            preds = torch.sigmoid(model(x))\n",
    "            preds = (preds > 0.5).float()\n",
    "            num_correct += (preds == y).sum()\n",
    "            num_pixels += torch.numel(preds)\n",
    "            dice_score += (2 * (preds * y).sum()) / (\n",
    "                (preds + y).sum() + 1e-8\n",
    "            )\n",
    "\n",
    "    print(\n",
    "        f\"Got {num_correct}/{num_pixels} with acc {num_correct/num_pixels*100:.2f}\"\n",
    "    )\n",
    "    print(f\"Dice score: {dice_score/len(loader)}\")\n",
    "    model.train()\n",
    "    \n",
    "def save_preds_as_imgs(\n",
    "    loader, model, folder=\"saved_images/\", device=\"cuda\"\n",
    "):\n",
    "    model.eval()\n",
    "    for idx, (x, y) in enumerate(loader):\n",
    "        x = x.to(device=device)\n",
    "        with torch.no_grad():\n",
    "            preds = torch.sigmoid(model(x))\n",
    "            preds = (preds > 0.5).float()\n",
    "        torchvision.utils.save_image(\n",
    "            preds, f\"{folder}/pred_{idx}.png\"\n",
    "        )\n",
    "        torchvision.utils.save_image(y.unsqueeze(1), f\"{folder}{idx}.png\")\n",
    "\n",
    "    model.train()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "import albumentations as albu\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "from tqdm import tqdm\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "\n",
    "# Hyperparameters etc.\n",
    "LEARNING_RATE = 1e-5\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "BATCH_SIZE = 4\n",
    "NUM_EPOCHS = 10\n",
    "NUM_WORKERS = 4\n",
    "IMAGE_HEIGHT = 256  # 1280 originally\n",
    "IMAGE_WIDTH = 256  # 1918 originally\n",
    "PIN_MEMORY = True\n",
    "TRAIN_IMG_DIR = \"input/tiff/train/\"\n",
    "TRAIN_MASK_DIR = \"input/tiff/train_labels/\"\n",
    "VAL_IMG_DIR = \"input/tiff/val/\"\n",
    "VAL_MASK_DIR = \"input/tiff/val_labels/\"\n",
    "\n",
    "def train_fn(loader, model, optimizer, loss_fn, scaler):\n",
    "    loop = tqdm(loader)\n",
    "\n",
    "    for batch_idx, (data, targets) in enumerate(loop):\n",
    "        data = data.to(device=DEVICE)\n",
    "        targets = targets.float().to(device=DEVICE)\n",
    "\n",
    "        # forward\n",
    "        with torch.cuda.amp.autocast():\n",
    "            predictions = model(data)\n",
    "            loss = loss_fn(predictions, targets)\n",
    "\n",
    "        # backward\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        scaler.scale(loss).backward()\n",
    "        scaler.step(optimizer)\n",
    "        scaler.update()\n",
    "\n",
    "        # update tqdm loop\n",
    "        loop.set_postfix(loss=loss.item())\n",
    "\n",
    "\n",
    "def main():\n",
    "    train_transform = albu.Compose(\n",
    "        [\n",
    "            albu.Resize(height=IMAGE_HEIGHT, width=IMAGE_WIDTH),\n",
    "            albu.Rotate(limit=35, p=1.0),\n",
    "            albu.HorizontalFlip(p=0.5),\n",
    "            albu.VerticalFlip(p=0.1),\n",
    "            albu.Normalize(mean=[0.0, 0.0, 0.0], std=[1.0, 1.0, 1.0], max_pixel_value=255.0),\n",
    "\n",
    "            ToTensorV2()\n",
    "        ],\n",
    "    )\n",
    "\n",
    "    val_transforms = albu.Compose(\n",
    "        [\n",
    "            albu.Resize(height=IMAGE_HEIGHT, width=IMAGE_WIDTH),\n",
    "            albu.Normalize(mean=[0.0, 0.0, 0.0], std=[1.0, 1.0, 1.0], max_pixel_value=255.0),\n",
    "            ToTensorV2()\n",
    "        ],\n",
    "    )\n",
    "\n",
    "    model = Unet(in_c=3, out_c=1).to(DEVICE)\n",
    "    loss_fn = DiceLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
    "\n",
    "    train_loader, val_loader = get_loaders(\n",
    "        TRAIN_IMG_DIR,\n",
    "        TRAIN_MASK_DIR,\n",
    "        VAL_IMG_DIR,\n",
    "        VAL_MASK_DIR,\n",
    "        BATCH_SIZE,\n",
    "        train_transform,\n",
    "        val_transforms,\n",
    "        # NUM_WORKERS,\n",
    "        PIN_MEMORY,\n",
    "    )\n",
    "\n",
    "\n",
    "\n",
    "    # check_accuracy(val_loader, model, device=DEVICE)\n",
    "    scaler = torch.cuda.amp.GradScaler()\n",
    "\n",
    "    for epoch in range(NUM_EPOCHS):\n",
    "        train_fn(train_loader, model, optimizer, loss_fn, scaler)\n",
    "\n",
    "        # save model\n",
    "        checkpoint = {\n",
    "            \"state_dict\": model.state_dict(),\n",
    "            \"optimizer\":optimizer.state_dict(),\n",
    "        }\n",
    "        save_checkpoint(checkpoint, f\"checkpoints/{epoch}_.pth\")\n",
    "\n",
    "        # check accuracy\n",
    "        check_accuracy(val_loader, model, device=DEVICE)\n",
    "\n",
    "        # print some examples to a folder\n",
    "        save_preds_as_imgs(\n",
    "            val_loader, model, folder=\"saved_images/\", device=DEVICE\n",
    "        )\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-18T04:51:29.315363200Z",
     "start_time": "2023-05-18T04:51:29.295368300Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/277 [00:00<?, ?it/s]C:\\Users\\dimas\\PycharmProjects\\Road_segemtation\\venv\\lib\\site-packages\\torch\\autograd\\__init__.py:200: UserWarning: Error detected in ConvolutionBackward0. No forward pass information available. Enable detect anomaly during forward pass for more information. (Triggered internally at ..\\torch\\csrc\\autograd\\python_anomaly_mode.cpp:97.)\n",
      "  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "  0%|          | 0/277 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "one of the variables needed for gradient computation has been modified by an inplace operation: [torch.cuda.HalfTensor [4, 128, 256, 256]], which is output 0 of AddBackward0, is at version 1; expected version 0 instead. Hint: the backtrace further above shows the operation that failed to compute its gradient. The variable in question was changed in there or anywhere later. Good luck!",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mRuntimeError\u001B[0m                              Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[38], line 1\u001B[0m\n\u001B[1;32m----> 1\u001B[0m \u001B[43mmain\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n",
      "Cell \u001B[1;32mIn[37], line 91\u001B[0m, in \u001B[0;36mmain\u001B[1;34m()\u001B[0m\n\u001B[0;32m     88\u001B[0m scaler \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39mcuda\u001B[38;5;241m.\u001B[39mamp\u001B[38;5;241m.\u001B[39mGradScaler()\n\u001B[0;32m     90\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m epoch \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(NUM_EPOCHS):\n\u001B[1;32m---> 91\u001B[0m     \u001B[43mtrain_fn\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtrain_loader\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43moptimizer\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mloss_fn\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mscaler\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     93\u001B[0m     \u001B[38;5;66;03m# save model\u001B[39;00m\n\u001B[0;32m     94\u001B[0m     checkpoint \u001B[38;5;241m=\u001B[39m {\n\u001B[0;32m     95\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mstate_dict\u001B[39m\u001B[38;5;124m\"\u001B[39m: model\u001B[38;5;241m.\u001B[39mstate_dict(),\n\u001B[0;32m     96\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124moptimizer\u001B[39m\u001B[38;5;124m\"\u001B[39m:optimizer\u001B[38;5;241m.\u001B[39mstate_dict(),\n\u001B[0;32m     97\u001B[0m     }\n",
      "Cell \u001B[1;32mIn[37], line 40\u001B[0m, in \u001B[0;36mtrain_fn\u001B[1;34m(loader, model, optimizer, loss_fn, scaler)\u001B[0m\n\u001B[0;32m     38\u001B[0m optimizer\u001B[38;5;241m.\u001B[39mzero_grad()\n\u001B[0;32m     39\u001B[0m torch\u001B[38;5;241m.\u001B[39mautograd\u001B[38;5;241m.\u001B[39mset_detect_anomaly(\u001B[38;5;28;01mTrue\u001B[39;00m)\n\u001B[1;32m---> 40\u001B[0m \u001B[43mscaler\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mscale\u001B[49m\u001B[43m(\u001B[49m\u001B[43mloss\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbackward\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     41\u001B[0m scaler\u001B[38;5;241m.\u001B[39mstep(optimizer)\n\u001B[0;32m     42\u001B[0m scaler\u001B[38;5;241m.\u001B[39mupdate()\n",
      "File \u001B[1;32m~\\PycharmProjects\\Road_segemtation\\venv\\lib\\site-packages\\torch\\_tensor.py:487\u001B[0m, in \u001B[0;36mTensor.backward\u001B[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001B[0m\n\u001B[0;32m    477\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m has_torch_function_unary(\u001B[38;5;28mself\u001B[39m):\n\u001B[0;32m    478\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m handle_torch_function(\n\u001B[0;32m    479\u001B[0m         Tensor\u001B[38;5;241m.\u001B[39mbackward,\n\u001B[0;32m    480\u001B[0m         (\u001B[38;5;28mself\u001B[39m,),\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    485\u001B[0m         inputs\u001B[38;5;241m=\u001B[39minputs,\n\u001B[0;32m    486\u001B[0m     )\n\u001B[1;32m--> 487\u001B[0m \u001B[43mtorch\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mautograd\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbackward\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    488\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mgradient\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mretain_graph\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcreate_graph\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43minputs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43minputs\u001B[49m\n\u001B[0;32m    489\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\PycharmProjects\\Road_segemtation\\venv\\lib\\site-packages\\torch\\autograd\\__init__.py:200\u001B[0m, in \u001B[0;36mbackward\u001B[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001B[0m\n\u001B[0;32m    195\u001B[0m     retain_graph \u001B[38;5;241m=\u001B[39m create_graph\n\u001B[0;32m    197\u001B[0m \u001B[38;5;66;03m# The reason we repeat same the comment below is that\u001B[39;00m\n\u001B[0;32m    198\u001B[0m \u001B[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001B[39;00m\n\u001B[0;32m    199\u001B[0m \u001B[38;5;66;03m# calls in the traceback and some print out the last line\u001B[39;00m\n\u001B[1;32m--> 200\u001B[0m \u001B[43mVariable\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_execution_engine\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrun_backward\u001B[49m\u001B[43m(\u001B[49m\u001B[43m  \u001B[49m\u001B[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001B[39;49;00m\n\u001B[0;32m    201\u001B[0m \u001B[43m    \u001B[49m\u001B[43mtensors\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mgrad_tensors_\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mretain_graph\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcreate_graph\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43minputs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    202\u001B[0m \u001B[43m    \u001B[49m\u001B[43mallow_unreachable\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43maccumulate_grad\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m)\u001B[49m\n",
      "\u001B[1;31mRuntimeError\u001B[0m: one of the variables needed for gradient computation has been modified by an inplace operation: [torch.cuda.HalfTensor [4, 128, 256, 256]], which is output 0 of AddBackward0, is at version 1; expected version 0 instead. Hint: the backtrace further above shows the operation that failed to compute its gradient. The variable in question was changed in there or anywhere later. Good luck!"
     ]
    }
   ],
   "source": [
    "main()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-18T04:51:31.487390Z",
     "start_time": "2023-05-18T04:51:30.424870800Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
